apiVersion: batch/v1
kind: Job
metadata:
  name: {{ .Values.webapp.name }}-{{ randAlphaNum 5 | lower }}
  namespace: {{ .Release.Namespace }}
  labels:
    app: {{ .Values.webapp.name }}
    group: {{ .Values.webapp.group }}
spec:
  template:
    metadata:
      labels:
        app: {{ .Values.webapp.name }}
    spec:
      restartPolicy: Never
      volumes:
        - name: {{ .Values.webapp.volume1.name }}
          nfs:
            server: {{ .Values.webapp.volume1.server }}
            path: {{ .Values.webapp.volume1.path }}
            readOnly: {{ .Values.webapp.volume1.readOnly }}
        - name: {{ .Values.webapp.volume2.name }}
          persistentVolumeClaim:
            claimName: {{ .Values.webapp.volume2.name }}
        - name: {{ .Values.webapp.volume3.name }}
          persistentVolumeClaim:
            claimName: {{ .Values.webapp.volume3.name }}
        - name: {{ .Values.webapp.extraVolumes.name }}
          emptyDir:
            medium: {{ .Values.webapp.extraVolumes.emptyDir.medium }}
            sizeLimit: {{ .Values.webapp.extraVolumes.emptyDir.sizeLimit }}
      runtimeClassName: nvidia
      securityContext:
        fsGroup: 1000
      #  runAsUser: 1000
      #  capabilities:
      #    add: ["IPC_LOCK"]
      containers:
      - name: {{ .Values.webapp.name }}
        image: {{ .Values.webapp.container.image }}
        securityContext:
          runAsUser: 1000
          capabilities:
            add: ["IPC_LOCK"]
        imagePullPolicy: {{ .Values.webapp.imagePullPolicy }}
        command: ["/bin/bash", "-c"]
        args:
          - |
            #rm -rf /checkpoint/*
            ulimit -l $(ulimit -H -l)
            echo "import torch; print('CUDA available?', torch.cuda.is_available())" > /workspace/test.py
            conda run -n credit python /workspace/test.py
            echo shmem
            df -h /dev/shm
            echo cpu instruction support
            cat /proc/cpuinfo |grep flags | head -1
            checkpointDir=/glade/campaign/cisl/vast/pearse/wxformer_1h/finetune_final \
            [ -z "$(find $checkpointDir -mindepth 1 -print -quit)" ] && cp -r "$checkpointDir" /checkpoint
            echo "scott's dir"
            ls /glade/campaign/cisl/vast/pearse/wxformer_1h/finetune_final
            export PATH=/home/ubuntu/.local/bin:$PATH
            echo $PATH
            git clone -q https://github.com/NCAR/CIRRUS-MILES-CREDIT.git
            git pull -q
            conda run -n credit python -m pip install -q -e .
            #git checkout djgagne
            cd applications
            echo conda contents
            ls /opt/conda/envs/credit/lib/python3.11/site-packages | grep netCDF4
            ls -lrth /opt/conda/envs/credit
            #sudo chown -R 1000:1000 /opt/conda/envs/credit
            #chown -R 1000:1000 /opt/conda/envs/credit
            ls -lrth /opt/conda/envs/credit
            #conda install -y -n credit -c conda-forge "hdf5=*=nompi_*" "libnetcdf=*=nompi_*" "netcdf4" --user
            conda list -n credit | egrep "netCDF4|libnetcdf|hdf5|numpy|ucx"
            echo "GFS INIT!!!!"
            ulimit -l unlimited; LD_LIBRARY_PATH=/opt/conda/envs/credit/lib:$LD_LIBRARY_PATH \
            conda run -n credit python gfs_init.py -c /workspace/miles-credit/CIRRUS-MILES-CREDIT/model_predict_old.yml
            #conda install -n credit cftime
            echo "output3"
            ls -a /output
            cp /output/gfs_init_20250702_0000.zarr/.zmetadata /output
            #chmod -R 777 /output
            mkdir -p /output/wxformer_1h_gfs
            #kchmod -R 777 /output/wxformer_1h_gfs
            echo "ROLLOUT REALTIME"
            bash /usr/local/bin/gpu-test
            #conda run -n credit conda install netcdf-c
            #conda run -n credit ncdump -h /checkpoint/solar_irradiance_2025-01-01_0000_2025-12-31_2300.nc
            ls -lrth /checkpoint
            touch /checkpoint/solar_irradiance_2025-01-01_0000_2025-12-31_2300.nc
            echo foo?
            #sed -i "151a\        print('FILENAME!' + filename)" /workspace/miles-credit/credit/data.py
            #LD_LIBRARY_PATH=/opt/conda/envs/credit/lib:$LD_LIBRARY_PATH OMP_NUM_THREADS=1 MKL_NUM_THREADS=1 \
            #conda run -n credit python rollout_realtime.py
            echo bar
            ulimit -l unlimited
            ulimit -l
            #conda run -n credit python rollout_realtime.py -c /workspace/miles-credit/CIRRUS-MILES-CREDIT/model_predict_old.yml
            ls -a /output/wxformer_1h_gfs
            ls -a /output/wxformer_1h_gfs/finetune_final
#
# copy scalers
            #echo forcing!
            #ls /glade/campaign/cisl/vast/pearse/save_loc_dynamic_forcing/solar_irradiance_2025-01-01_0000_2025-12-31_2300.nc
            #echo static norm!
            #ls /glade/campaign/cisl/vast/pearse/static_scalers/gfs_static_norm.nc
            #echo mean!
            #ls /glade/campaign/cisl/vast/pearse/static_scalers/mean_1h_1979_2018_16lev_0.25deg.nc
            #echo std!
            #ls /glade/campaign/cisl/vast/pearse/static_scalers/std_residual_1h_1979_2018_16lev_0.25deg.nc
#
            #printf '{\n    "zarr_format": 2\n}\n' > /output/.zgroup
            #
            #
            #python applications/gfs_init.py
            #conda run -n credit python -c "import torch; print(\"CUDA available?\", torch.cuda.is_available())"
            #bash /usr/local/bin/gpu-test &&
            #ls /usr/local/bin/gpu-test &&
            
        #command: ["/bin/bash", "-c"]
        #args:
        #  - |
        #    echo foo;
#        command: ["/bin/bash", "-c"]
#        args:
#          - |
#            echo "Starting job...";
#            export TZ=MST;
#            RESULT=$(date);
#            echo "The current date is: $RESULT";
        #command: ["/bin/bash", "-c"]
        #args:
        #  - |
        #    ls;
        #    ls /usr/local/bin/gpu-test;
        #    /usr/local/bin/gpu-test;
        #args: ["-c", "/usr/local/bin/gpu-test"]
        tty: true
        resources:
          limits:
            memory: {{ .Values.webapp.container.limits.memory }}
            cpu: {{ .Values.webapp.container.limits.cpu }}
            nvidia.com/gpu: "1"
          requests:
            memory: {{ .Values.webapp.container.requests.memory }}
            cpu: {{ .Values.webapp.container.requests.cpu }}
            nvidia.com/gpu: "1"
        volumeMounts:
        - mountPath: /glade/campaign
          name: {{ .Values.webapp.volume1.name }}
        - mountPath: /output
          name: {{ .Values.webapp.volume2.name }}
        - mountPath: /checkpoint
          name: {{ .Values.webapp.volume3.name }}
        - mountPath: /dev/shm
          name: {{ .Values.webapp.extraVolumes.name }}
